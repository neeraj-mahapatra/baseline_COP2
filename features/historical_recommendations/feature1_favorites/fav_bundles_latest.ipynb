{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from typing import List, Dict, Tuple, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df: pd.DataFrame, freq_col: str = 'purchase_frequency', rec_col: str = 'recency') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize frequency and recency using min-max normalization:\n",
    "    normalized_value = (value - min) / (max - min)\n",
    "    Adds two new columns: 'normalized_f' and 'normalized_r'.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame containing the data to normalize.\n",
    "    freq_col : str, optional\n",
    "        The name of the column representing purchase frequency. Default is 'purchase_frequency'.\n",
    "    rec_col : str, optional\n",
    "        The name of the column representing recency. Default is 'recency'.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with two new normalized columns added.\n",
    "    \"\"\"\n",
    "    for col, norm_col in [(freq_col, 'normalized_f'), (rec_col, 'normalized_r')]:\n",
    "        min_val = df[col].min()  # Find the minimum value in the column\n",
    "        max_val = df[col].max()  # Find the maximum value in the column\n",
    "        if max_val > min_val:\n",
    "            # Apply min-max normalization\n",
    "            df[norm_col] = (df[col] - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            # Handle case where all values are identical to avoid division by zero\n",
    "            df[norm_col] = 1.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_score(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the normalized_score for each product as the sum of normalized frequency and normalized recency.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame containing normalized frequency ('normalized_f') and recency ('normalized_r').\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with a new column 'normalized_score' added.\n",
    "    \"\"\"\n",
    "    df['normalized_score'] = df['normalized_f'] + df['normalized_r']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_business_score(subset: Tuple[Tuple[Any, ...], ...]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate a business-specific score for a given subset of products.\n",
    "    Customize this logic as per business requirements.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    subset : Tuple of Tuples\n",
    "        A subset of products, where each product is represented as a tuple.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        The business-specific score for the subset.\n",
    "    \"\"\"\n",
    "    # Example placeholder: assign a constant value\n",
    "    # TODO: Replace with actual business logic\n",
    "    return 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_category_unique(subset: Tuple[Tuple[Any, ...], ...]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if all categories in the subset are unique.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    subset : Tuple of Tuples\n",
    "        A subset of products.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    bool\n",
    "        True if all categories are unique, False otherwise.\n",
    "    \"\"\"\n",
    "    categories = [p[1] for p in subset]  # Extract the category from each product\n",
    "    return len(set(categories)) == len(categories)  # Check for uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_budget(subset: Tuple[Tuple[Any, ...], ...], budget: float) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the sum of prices in the subset does not exceed the budget.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    subset : Tuple of Tuples\n",
    "        A subset of products.\n",
    "    budget : float\n",
    "        The maximum allowed total price for the subset.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    bool\n",
    "        True if total price is within budget, False otherwise.\n",
    "    \"\"\"\n",
    "    total_price = sum(p[2] for p in subset)  # Sum the prices of all products in the subset\n",
    "    return total_price <= budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_final_score(subset: Tuple[Tuple[Any, ...], ...]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the final score for a given subset of products.\n",
    "    final_score = sum of normalized_score + business_score\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    subset : Tuple of Tuples\n",
    "        A subset of products.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        The final score for the subset.\n",
    "    \"\"\"\n",
    "    base_score = sum(p[3] for p in subset)  # Sum of normalized scores (assuming p[3] is normalized_score)\n",
    "    business = calculate_business_score(subset)  # Business-specific score\n",
    "    return base_score + business\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_valid_bundles(\n",
    "    products: List[Tuple[int, str, float, float]],\n",
    "    budget: float,\n",
    "    min_bundle_size: int = 2\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate all valid bundles of products that:\n",
    "    - Have at least min_bundle_size products\n",
    "    - Have unique categories\n",
    "    - Are within the budget\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    products : List of Tuples\n",
    "        Each product is represented as a tuple: (product_id, category, price, normalized_score).\n",
    "    budget : float\n",
    "        The maximum allowed total price for a bundle.\n",
    "    min_bundle_size : int, optional\n",
    "        The minimum number of products required in a bundle. Default is 2.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    List of Dicts\n",
    "        Each dictionary represents a valid bundle with its products, total price, and score.\n",
    "    \"\"\"\n",
    "    valid_bundles = []\n",
    "    n = len(products)\n",
    "    for r in range(min_bundle_size, n + 1):\n",
    "        # Generate all possible combinations of size r\n",
    "        for subset in combinations(products, r):\n",
    "            if is_category_unique(subset) and is_within_budget(subset, budget):\n",
    "                final_score = calculate_final_score(subset)\n",
    "                bundle_price = sum(p[2] for p in subset)  # Total price of the bundle\n",
    "                valid_bundles.append({\n",
    "                    'bundle': subset,  # The subset of products\n",
    "                    'price': bundle_price,\n",
    "                    'score': final_score\n",
    "                })\n",
    "    return valid_bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_extendable(\n",
    "    bundle: Dict,\n",
    "    products: List[Tuple[int, str, float, float]],\n",
    "    budget: float\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Check if a given bundle can be extended by adding another product without violating constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    bundle : Dict\n",
    "        The current bundle with keys 'bundle', 'price', and 'score'.\n",
    "    products : List of Tuples\n",
    "        All available products.\n",
    "    budget : float\n",
    "        The maximum allowed total price for a bundle.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    bool\n",
    "        True if the bundle can be extended, False otherwise.\n",
    "    \"\"\"\n",
    "    current_ids = {p[0] for p in bundle['bundle']}  # Current product IDs in the bundle\n",
    "    current_categories = {p[1] for p in bundle['bundle']}  # Current categories in the bundle\n",
    "    current_price = bundle['price']  # Current total price\n",
    "    \n",
    "    for p in products:\n",
    "        if p[0] not in current_ids:\n",
    "            # Check if adding this product maintains unique categories and stays within budget\n",
    "            if p[1] not in current_categories and (current_price + p[2] <= budget):\n",
    "                return True  # Bundle can be extended\n",
    "    return False  # No valid extensions found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_maximal_bundles(\n",
    "    products: List[Tuple[int, str, float, float]],\n",
    "    budget: float,\n",
    "    min_bundle_size: int = 2\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate only maximal bundles:\n",
    "    A maximal bundle is one that cannot be extended further without violating constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    products : List of Tuples\n",
    "        Each product is represented as a tuple: (product_id, category, price, normalized_score).\n",
    "    budget : float\n",
    "        The maximum allowed total price for a bundle.\n",
    "    min_bundle_size : int, optional\n",
    "        The minimum number of products required in a bundle. Default is 2.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    List of Dicts\n",
    "        Each dictionary represents a maximal bundle with its products, total price, and score.\n",
    "    \"\"\"\n",
    "    all_bundles = generate_all_valid_bundles(products, budget, min_bundle_size)\n",
    "    maximal_bundles = []\n",
    "    for b in all_bundles:\n",
    "        if not is_extendable(b, products, budget):\n",
    "            maximal_bundles.append(b)  # Only add if the bundle cannot be extended\n",
    "    return maximal_bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bundle_rows_for_consultant(\n",
    "    group: pd.DataFrame,\n",
    "    consultant_id: Any,\n",
    "    maximal_bundles: List[Dict]\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Convert maximal bundles into rows. Each row represents one bundle:\n",
    "    - consultant_id\n",
    "    - products: list of product_ids in the bundle\n",
    "    - price: total price of the bundle\n",
    "    - total_normalized_score: sum of normalized_score of products in the bundle\n",
    "    - bundle_score: final score of the bundle\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    group : pd.DataFrame\n",
    "        The DataFrame group corresponding to a single consultant.\n",
    "    consultant_id : Any\n",
    "        The identifier for the consultant.\n",
    "    maximal_bundles : List of Dicts\n",
    "        The list of maximal bundles for this consultant.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    List of Dicts\n",
    "        Each dictionary represents a bundle row ready for output.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for mb in maximal_bundles:\n",
    "        product_ids = [p[0] for p in mb['bundle']]  # Extract product IDs\n",
    "        # Extract product information from the group DataFrame\n",
    "        subset_df = group[group['product_id'].isin(product_ids)]\n",
    "        \n",
    "        total_normalized_score = subset_df['normalized_score'].sum()  # Sum of normalized scores\n",
    "        # The mb['score'] is already the final_score = total_normalized_score + business_score\n",
    "        \n",
    "        result_row = {\n",
    "            'consultant_id': consultant_id,\n",
    "            'products': product_ids,\n",
    "            'price': mb['price'],\n",
    "            'total_normalized_score': total_normalized_score,\n",
    "            'bundle_score': mb['score']\n",
    "        }\n",
    "        results.append(result_row)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_csv(\n",
    "    input_csv: str,\n",
    "    output_csv: str,\n",
    "    budget: float,\n",
    "    min_bundle_size: int = 2,\n",
    "    max_rows: int = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Main function to:\n",
    "    - Load data from input CSV\n",
    "    - Normalize frequency and recency\n",
    "    - Compute normalized_score\n",
    "    - Generate maximal bundles per consultant\n",
    "    - Output results to a CSV (one row per bundle)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_csv : str\n",
    "        Path to the input CSV file.\n",
    "    output_csv : str\n",
    "        Path where the output CSV file should be written.\n",
    "    budget : float\n",
    "        The purchasing power or maximum allowed total price for a bundle.\n",
    "    min_bundle_size : int, optional\n",
    "        The minimum number of products required in a bundle. Default is 2.\n",
    "    max_rows : int, optional\n",
    "        If given, read only the specified number of rows from the input file.\n",
    "    \"\"\"\n",
    "    # Load input CSV into a DataFrame\n",
    "    df = pd.read_csv(input_csv)\n",
    "    if max_rows is not None:\n",
    "        df = df.head(max_rows)  # Limit the number of rows if max_rows is specified\n",
    "    \n",
    "    # Normalize frequency and recency columns\n",
    "    df = normalize_columns(df, freq_col='purchase_frequency', rec_col='recency')\n",
    "    \n",
    "    # Calculate normalized_score for each product\n",
    "    df = calculate_normalized_score(df)\n",
    "    \n",
    "    # Initialize a list to hold all result rows\n",
    "    results = []\n",
    "    \n",
    "    # Process each consultant separately by grouping the DataFrame\n",
    "    for consultant_id, group in df.groupby('consultant_id'):\n",
    "        # Convert relevant product information into a list of tuples\n",
    "        # Each tuple contains: (product_id, category, price, normalized_score)\n",
    "        products = list(group[['product_id', 'category', 'price', 'normalized_score']].itertuples(index=False, name=None))\n",
    "        \n",
    "        # Generate maximal bundles for this consultant based on constraints\n",
    "        maximal = generate_maximal_bundles(products, budget, min_bundle_size)\n",
    "        \n",
    "        # Convert each maximal bundle into a result row\n",
    "        consultant_results = build_bundle_rows_for_consultant(group, consultant_id, maximal)\n",
    "        results.extend(consultant_results)  # Add to the overall results\n",
    "    \n",
    "    # Convert the list of result dictionaries into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Optional: Sort the results for better readability or specific analysis\n",
    "    # For example, sort by consultant_id and then by bundle_score in descending order\n",
    "    results_df.sort_values(by=['consultant_id', 'bundle_score'], inplace=True, ascending=[True, False])\n",
    "    \n",
    "    # Write the final results to the specified output CSV file\n",
    "    results_df.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'purchase_frequency'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/baseline_COP2/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'purchase_frequency'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst_500_rows.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst_500_rows_res.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Set the budget constraint for bundles\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_bundle_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Set the minimum number of products in a bundle\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Optionally limit the number of rows processed\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m, in \u001b[0;36mprocess_csv\u001b[0;34m(input_csv, output_csv, budget, min_bundle_size, max_rows)\u001b[0m\n\u001b[1;32m     32\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mhead(max_rows)  \u001b[38;5;66;03m# Limit the number of rows if max_rows is specified\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Normalize frequency and recency columns\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpurchase_frequency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrec_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Calculate normalized_score for each product\u001b[39;00m\n\u001b[1;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m calculate_normalized_score(df)\n",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m, in \u001b[0;36mnormalize_columns\u001b[0;34m(df, freq_col, rec_col)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mNormalize frequency and recency using min-max normalization:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mnormalized_value = (value - min) / (max - min)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    The DataFrame with two new normalized columns added.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, norm_col \u001b[38;5;129;01min\u001b[39;00m [(freq_col, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_f\u001b[39m\u001b[38;5;124m'\u001b[39m), (rec_col, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_r\u001b[39m\u001b[38;5;124m'\u001b[39m)]:\n\u001b[0;32m---> 22\u001b[0m     min_val \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin()  \u001b[38;5;66;03m# Find the minimum value in the column\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     max_val \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mmax()  \u001b[38;5;66;03m# Find the maximum value in the column\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_val \u001b[38;5;241m>\u001b[39m min_val:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# Apply min-max normalization\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/baseline_COP2/venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/baseline_COP2/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'purchase_frequency'"
     ]
    }
   ],
   "source": [
    "\n",
    "process_csv(\n",
    "    input_csv='first_500_rows.csv',\n",
    "    output_csv='first_500_rows_res.csv',\n",
    "    budget=200,            # Set the budget constraint for bundles\n",
    "    min_bundle_size=2,     # Set the minimum number of products in a bundle\n",
    "    max_rows=500           # Optionally limit the number of rows processed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "P1  C1\n",
    "P2  C2\n",
    "P3  C1\n",
    "P4  C4\n",
    "P5  C5\n",
    "P6  C6\n",
    "\n",
    "p1, p2, P4\n",
    "p1, p2, p5\n",
    "\n",
    "category, sub category, type, sub type - type should not be same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 500 rows have been saved to first_500_rows.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file (replace 'input_file.csv' with the path to your input file)\n",
    "input_file = 'F1_test.csv'  # Replace with your file path\n",
    "output_file = 'first_500_rows.csv'  # Path for the output file\n",
    "\n",
    "# Read the input CSV\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Select the first 500 rows\n",
    "first_500_rows = data.head(500)\n",
    "\n",
    "# Save the first 500 rows to a new CSV file\n",
    "first_500_rows.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"The first 500 rows have been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More optimized approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from itertools import combinations\n",
    "# from typing import List, Dict, Tuple, Any\n",
    "\n",
    "# def normalize_columns(df: pd.DataFrame, freq_col: str = 'purchase_frequency', rec_col: str = 'recency') -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Normalize the frequency and recency columns using min-max normalization.\n",
    "#     normalized_value = (value - min) / (max - min)\n",
    "#     If all values are the same (min == max), normalization defaults them all to 1.0.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     df : pd.DataFrame\n",
    "#         The input DataFrame containing frequency and recency columns.\n",
    "#     freq_col : str\n",
    "#         The column name representing purchase frequency.\n",
    "#     rec_col : str\n",
    "#         The column name representing recency.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         The DataFrame with two new columns: 'normalized_f' and 'normalized_r'.\n",
    "#     \"\"\"\n",
    "#     for col, norm_col in [(freq_col, 'normalized_f'), (rec_col, 'normalized_r')]:\n",
    "#         min_val = df[col].min()\n",
    "#         max_val = df[col].max()\n",
    "#         if max_val > min_val:\n",
    "#             df[norm_col] = (df[col] - min_val) / (max_val - min_val)\n",
    "#         else:\n",
    "#             # If there's no range (min == max), set all values to 1 to avoid division by zero\n",
    "#             df[norm_col] = 1.0\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def calculate_normalized_score(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Calculate a 'normalized_score' as the sum of normalized frequency and normalized recency.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     df : pd.DataFrame\n",
    "#         The input DataFrame containing 'normalized_f' and 'normalized_r' columns.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         The DataFrame with an additional 'normalized_score' column.\n",
    "#     \"\"\"\n",
    "#     df['normalized_score'] = df['normalized_f'] + df['normalized_r']\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def calculate_business_score(subset: Tuple[Tuple[Any, ...], ...]) -> float:\n",
    "#     \"\"\"\n",
    "#     Calculate a business-specific score for a given subset of products.\n",
    "#     This is a placeholder function. Modify this logic per business requirements.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     subset : tuple of tuples\n",
    "#         Each element is a product represented by (product_id, category, price, normalized_score).\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     float\n",
    "#         The business-specific score. Currently returns a constant value for demonstration.\n",
    "#     \"\"\"\n",
    "#     return 2.0\n",
    "\n",
    "\n",
    "# def generate_all_valid_bundles(\n",
    "#     products: List[Tuple[int, str, float, float]],\n",
    "#     budget: float,\n",
    "#     min_bundle_size: int = 2\n",
    "# ) -> List[Dict]:\n",
    "#     \"\"\"\n",
    "#     Generate all valid bundles of products that:\n",
    "#     - Have at least `min_bundle_size` products.\n",
    "#     - Contain unique categories (no category repeated).\n",
    "#     - Are within the given budget.\n",
    "\n",
    "#     This function is optimized compared to a naive approach:\n",
    "#     - We use a category-to-integer mapping and a bitmask to quickly check if a category is unique.\n",
    "#     - We integrate the checks for budget and category uniqueness directly as we build the subset.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     products : list of tuples\n",
    "#         Each tuple: (product_id, category, price, normalized_score)\n",
    "#     budget : float\n",
    "#         The maximum allowed total price for a bundle.\n",
    "#     min_bundle_size : int\n",
    "#         The minimum number of products in a valid bundle.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     list of dict\n",
    "#         Each dict has keys: 'bundle', 'price', 'score'.\n",
    "#         'bundle' is a tuple of product tuples, 'price' is the total bundle price, 'score' is the final score.\n",
    "#     \"\"\"\n",
    "#     # Map each unique category to an integer ID for bitmask operations\n",
    "#     category_to_id = {}\n",
    "#     cat_id = 0\n",
    "#     for _, cat, _, _ in products:\n",
    "#         if cat not in category_to_id:\n",
    "#             category_to_id[cat] = cat_id\n",
    "#             cat_id += 1\n",
    "\n",
    "#     valid_bundles = []\n",
    "#     n = len(products)\n",
    "\n",
    "#     # Generate combinations of products of size r, for r from min_bundle_size to n\n",
    "#     for r in range(min_bundle_size, n + 1):\n",
    "#         for subset in combinations(products, r):\n",
    "#             category_mask = 0  # bitmask to track used categories\n",
    "#             total_price = 0.0\n",
    "#             total_normalized_score = 0.0\n",
    "#             valid = True  # flag to indicate if this subset is valid\n",
    "\n",
    "#             # Check each product in the subset\n",
    "#             for p in subset:\n",
    "#                 # p is (product_id, category, price, normalized_score)\n",
    "#                 cid = category_to_id[p[1]]  # get the integer ID of the category\n",
    "#                 # Check if this category is already used by checking the category_mask bit\n",
    "#                 if (category_mask & (1 << cid)) != 0:\n",
    "#                     # Category already used in this subset; not valid\n",
    "#                     valid = False\n",
    "#                     break\n",
    "#                 category_mask |= (1 << cid)  # mark this category as used\n",
    "\n",
    "#                 # Accumulate price and check against budget\n",
    "#                 total_price += p[2]\n",
    "#                 if total_price > budget:\n",
    "#                     # Over the allowed budget; no need to continue\n",
    "#                     valid = False\n",
    "#                     break\n",
    "\n",
    "#                 # Accumulate the total normalized score\n",
    "#                 total_normalized_score += p[3]\n",
    "\n",
    "#             if not valid:\n",
    "#                 # This subset fails either category uniqueness or budget constraints\n",
    "#                 continue\n",
    "\n",
    "#             # If we reach here, the subset is valid\n",
    "#             # Calculate the final score (normalized_score sum + business_score)\n",
    "#             business = calculate_business_score(subset)\n",
    "#             final_score = total_normalized_score + business\n",
    "\n",
    "#             valid_bundles.append({\n",
    "#                 'bundle': subset,\n",
    "#                 'price': total_price,\n",
    "#                 'score': final_score\n",
    "#             })\n",
    "\n",
    "#     return valid_bundles\n",
    "\n",
    "\n",
    "# def is_extendable(\n",
    "#     bundle: Dict,\n",
    "#     products: List[Tuple[int, str, float, float]],\n",
    "#     budget: float\n",
    "# ) -> bool:\n",
    "#     \"\"\"\n",
    "#     Check if a given bundle can be extended by adding another product without violating constraints:\n",
    "#     - Adding another product must not break category uniqueness.\n",
    "#     - Adding another product must remain within the budget.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     bundle : dict\n",
    "#         A dictionary representing a current bundle with keys: 'bundle', 'price', 'score'.\n",
    "#     products : list of tuples\n",
    "#         All available products (product_id, category, price, normalized_score).\n",
    "#     budget : float\n",
    "#         Maximum allowed total price for an extended bundle.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     bool\n",
    "#         True if there is at least one product that can be added without violating constraints, False otherwise.\n",
    "#     \"\"\"\n",
    "#     # Extract current bundle info for quick checks\n",
    "#     current_ids = {p[0] for p in bundle['bundle']}\n",
    "#     current_categories = {p[1] for p in bundle['bundle']}\n",
    "#     current_price = bundle['price']\n",
    "\n",
    "#     # Try to find any product not in the bundle and not sharing a category, and fits the budget\n",
    "#     for p in products:\n",
    "#         if p[0] not in current_ids:\n",
    "#             if p[1] not in current_categories and (current_price + p[2] <= budget):\n",
    "#                 return True\n",
    "#     return False\n",
    "\n",
    "\n",
    "# def generate_maximal_bundles(\n",
    "#     products: List[Tuple[int, str, float, float]],\n",
    "#     budget: float,\n",
    "#     min_bundle_size: int = 2\n",
    "# ) -> List[Dict]:\n",
    "#     \"\"\"\n",
    "#     Generate only maximal bundles. A maximal bundle is one that cannot be extended further\n",
    "#     without violating the category uniqueness or budget constraints.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     products : list of tuples\n",
    "#         (product_id, category, price, normalized_score)\n",
    "#     budget : float\n",
    "#         Maximum budget for a bundle.\n",
    "#     min_bundle_size : int\n",
    "#         Minimum number of products in a bundle.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     list of dict\n",
    "#         Each dict represents a maximal bundle with keys: 'bundle', 'price', 'score'.\n",
    "#     \"\"\"\n",
    "#     all_bundles = generate_all_valid_bundles(products, budget, min_bundle_size)\n",
    "#     maximal_bundles = []\n",
    "#     for b in all_bundles:\n",
    "#         # A bundle is maximal if it cannot be extended\n",
    "#         if not is_extendable(b, products, budget):\n",
    "#             maximal_bundles.append(b)\n",
    "#     return maximal_bundles\n",
    "\n",
    "\n",
    "# def build_bundle_rows_for_consultant(\n",
    "#     group: pd.DataFrame,\n",
    "#     consultant_id: Any,\n",
    "#     maximal_bundles: List[Dict]\n",
    "# ) -> List[Dict]:\n",
    "#     \"\"\"\n",
    "#     Convert maximal bundle information into output rows for a given consultant.\n",
    "#     Each row includes:\n",
    "#     - consultant_id\n",
    "#     - a list of product_ids in the bundle\n",
    "#     - the total price of the bundle\n",
    "#     - the total normalized score of products in the bundle\n",
    "#     - the final bundle score (which includes business logic)\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     group : pd.DataFrame\n",
    "#         The consultant-specific subset of the DataFrame.\n",
    "#     consultant_id : Any\n",
    "#         The unique identifier of the consultant.\n",
    "#     maximal_bundles : list of dict\n",
    "#         The maximal bundles for this consultant.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     list of dict\n",
    "#         Each dict represents one row with keys:\n",
    "#         'consultant_id', 'products', 'price', 'total_normalized_score', 'bundle_score'.\n",
    "#     \"\"\"\n",
    "#     results = []\n",
    "#     for mb in maximal_bundles:\n",
    "#         product_ids = [p[0] for p in mb['bundle']]\n",
    "#         # subset_df filters only the products in the current bundle\n",
    "#         subset_df = group[group['product_id'].isin(product_ids)]\n",
    "\n",
    "#         # total_normalized_score should match the sum of p[3] for the products in the bundle\n",
    "#         total_normalized_score = subset_df['normalized_score'].sum()\n",
    "\n",
    "#         # mb['score'] = total_normalized_score + business_score\n",
    "#         result_row = {\n",
    "#             'consultant_id': consultant_id,\n",
    "#             'products': product_ids,\n",
    "#             'price': mb['price'],\n",
    "#             'total_normalized_score': total_normalized_score,\n",
    "#             'bundle_score': mb['score']\n",
    "#         }\n",
    "#         results.append(result_row)\n",
    "#     return results\n",
    "\n",
    "\n",
    "# def process_csv(\n",
    "#     input_csv: str,\n",
    "#     output_csv: str,\n",
    "#     budget: float,\n",
    "#     min_bundle_size: int = 2,\n",
    "#     max_rows: int = None\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Main function to:\n",
    "#     - Load data from input CSV\n",
    "#     - Normalize frequency and recency columns\n",
    "#     - Compute normalized_score\n",
    "#     - Generate maximal bundles per consultant\n",
    "#     - Write results to an output CSV\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     input_csv : str\n",
    "#         Path to the input CSV file.\n",
    "#     output_csv : str\n",
    "#         Path where the output CSV file should be written.\n",
    "#     budget : float\n",
    "#         The maximum allowed total price for a bundle.\n",
    "#     min_bundle_size : int\n",
    "#         The minimum number of products required in each bundle.\n",
    "#     max_rows : int, optional\n",
    "#         If specified, read only the first max_rows of the input CSV.\n",
    "#     \"\"\"\n",
    "#     # Load the input CSV\n",
    "#     df = pd.read_csv(input_csv)\n",
    "#     if max_rows is not None:\n",
    "#         df = df.head(max_rows)\n",
    "    \n",
    "#     # Normalize the necessary columns\n",
    "#     df = normalize_columns(df, freq_col='purchase_frequency', rec_col='recency')\n",
    "    \n",
    "#     # Compute the normalized_score for each product\n",
    "#     df = calculate_normalized_score(df)\n",
    "    \n",
    "#     # We will gather results for all consultants\n",
    "#     results = []\n",
    "    \n",
    "#     # Process each consultant separately\n",
    "#     for consultant_id, group in df.groupby('consultant_id'):\n",
    "#         # Convert product data to tuples for easier manipulation\n",
    "#         products = list(group[['product_id', 'category', 'price', 'normalized_score']].itertuples(index=False, name=None))\n",
    "        \n",
    "#         # Generate maximal bundles for this consultant\n",
    "#         maximal = generate_maximal_bundles(products, budget, min_bundle_size)\n",
    "        \n",
    "#         # Convert these bundles into row dictionaries for output\n",
    "#         consultant_results = build_bundle_rows_for_consultant(group, consultant_id, maximal)\n",
    "#         results.extend(consultant_results)\n",
    "    \n",
    "#     # Create a DataFrame from all results\n",
    "#     results_df = pd.DataFrame(results)\n",
    "    \n",
    "#     # Sort results by consultant_id, and within that by bundle_score (descending)\n",
    "#     results_df.sort_values(by=['consultant_id', 'bundle_score'], inplace=True, ascending=[True, False])\n",
    "    \n",
    "#     # Write the results to the output CSV\n",
    "#     results_df.to_csv(output_csv, index=False)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example usage (replace file paths as needed):\n",
    "#     process_csv('data/F1_test.csv', 'data/F1_test_res.csv', budget=200, min_bundle_size=2, max_rows=500)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
